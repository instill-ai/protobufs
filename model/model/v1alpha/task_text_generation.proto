syntax = "proto3";

package model.model.v1alpha;

// Google api
import "google/api/field_behavior.proto";
import "model/model/v1alpha/common.proto";

import "google/protobuf/struct.proto";

// reference to: https://github.com/instill-ai/connector/blob/main/pkg/openai/text_generation.go#L17
message PromptImage {
  oneof type {
    string prompt_image_url = 1;
    string prompt_image_base64 = 2;
  }
}
message Content {
    string type = 1;
    string content = 2;
    PromptImage prompt_image = 3;
}

// type Message struct {
// 	Role    string    `json:"role"`
// 	Content []Content `json:"content"`
// }

// type ImageUrl struct {
// 	Url string `json:"url"`
// }

// type Content struct {
// 	Type     string    `json:"type"`
// 	Text     *string   `json:"text,omitempty"`
// 	ImageUrl *ImageUrl `json:"image_url,omitempty"`
// }

// type TextCompletionInput struct {
// 	Prompt           string                `json:"prompt"`
// 	Images           []string              `json:"images"`
// 	ChatHistory      []*TextMessage        `json:"chat_history,omitempty"`
// 	Model            string                `json:"model"`
// 	SystemMessage    *string               `json:"system_message,omitempty"`
// 	Temperature      *float32              `json:"temperature,omitempty"`
// 	TopP             *float32              `json:"top_p,omitempty"`
// 	N                *int                  `json:"n,omitempty"`
// 	Stop             *string               `json:"stop,omitempty"`
// 	MaxTokens        *int                  `json:"max_tokens,omitempty"`
// 	PresencePenalty  *float32              `json:"presence_penalty,omitempty"`
// 	FrequencyPenalty *float32              `json:"frequency_penalty,omitempty"`
// 	ResponseFormat   *ResponseFormatStruct `json:"response_format,omitempty"`
// }

// TextGenerationInput represents the input of text generation task
message TextGenerationInput {
  // The prompt text
  string prompt = 1 [(google.api.field_behavior) = REQUIRED];

  // Optional fields
  repeated PromptImage prompt_images = 2 [(google.api.field_behavior) = OPTIONAL];
  repeated Content chat_history = 3 [(google.api.field_behavior) = OPTIONAL];
  optional string system_message = 4 [(google.api.field_behavior) = OPTIONAL];
  // The maximum number of tokens for model to generate
  optional int32 max_new_tokens = 5 [(google.api.field_behavior) = OPTIONAL];
  // The temperature for sampling
  optional float temperature = 6 [(google.api.field_behavior) = OPTIONAL];
  // Top k for sampling
  optional int32 top_k = 7 [(google.api.field_behavior) = OPTIONAL];
  // The seed
  optional int32 seed = 8 [(google.api.field_behavior) = OPTIONAL];
  // The extra parameters
  google.protobuf.Struct extra_params = 9 [(google.api.field_behavior) = OPTIONAL];
}

// TextGenerationOutput represents the output of text generation task
message TextGenerationOutput {
  // The text generated by the model
  string text = 1 [(google.api.field_behavior) = OUTPUT_ONLY];
}
